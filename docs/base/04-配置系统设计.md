# 04-配置系统设计

## 1. 配置系统概述

配置系统负责管理 Agent 的所有可配置参数，支持多层级配置、环境变量覆盖、配置验证和热更新。

### 1.1 设计目标
- **多层级配置**: 默认配置 < 配置文件 < 环境变量 < CLI 参数
- **类型安全**: TypeScript 类型定义和运行时验证
- **易用性**: 合理的默认值，最小化必需配置
- **灵活性**: 支持多模型配置、工具定制、日志级别调整

## 2. 配置文件结构

### 2.1 默认配置文件 (config/default.json)

```json
{
  "agent": {
    "maxIterations": 10,
    "enableReflection": true,
    "requireConfirmation": true,
    "autoSave": true,
    "saveInterval": 60000
  },

  "llm": {
    "planner": {
      "provider": "openai",
      "model": "gpt-4-turbo-preview",
      "temperature": 0.7,
      "maxTokens": 4096,
      "timeout": 60000
    },
    "executor": {
      "provider": "openai",
      "model": "gpt-4-turbo-preview",
      "temperature": 0.3,
      "maxTokens": 4096,
      "timeout": 120000
    },
    "reflector": {
      "provider": "openai",
      "model": "gpt-3.5-turbo",
      "temperature": 0.5,
      "maxTokens": 2048,
      "timeout": 60000
    }
  },

  "tools": {
    "enabled": [
      "code_query",
      "file_read",
      "file_write",
      "file_list",
      "snippet_save",
      "snippet_load",
      "snippet_list",
      "shell_exec",
      "ask_user"
    ],
    "workspaceDir": ".workspace",
    "maxFileSize": 10485760,
    "allowedExtensions": [
      ".js", ".ts", ".jsx", ".tsx",
      ".py", ".java", ".go", ".rs",
      ".c", ".cpp", ".h", ".hpp",
      ".json", ".yaml", ".yml",
      ".md", ".txt"
    ],
    "shellTimeout": 30000,
    "shellMaxBuffer": 10485760
  },

  "logging": {
    "level": "info",
    "outputDir": "logs",
    "enableConsole": true,
    "enableFile": true,
    "maxFileSize": 10485760,
    "maxFiles": 10,
    "format": "json"
  },

  "cli": {
    "theme": "dark",
    "showProgress": true,
    "confirmDangerous": true,
    "colorOutput": true,
    "verboseErrors": false
  },

  "storage": {
    "type": "file",
    "snippetDir": ".workspace/snippets",
    "sessionDir": ".workspace/sessions"
  }
}
```

### 2.2 环境变量配置 (.env)

```bash
# LLM API Keys
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...

# LLM Base URLs (可选)
OPENAI_BASE_URL=https://api.openai.com/v1
ANTHROPIC_BASE_URL=https://api.anthropic.com

# Agent 配置
AGENT_MAX_ITERATIONS=10
AGENT_ENABLE_REFLECTION=true
AGENT_REQUIRE_CONFIRMATION=true

# 日志配置
LOG_LEVEL=info
LOG_OUTPUT_DIR=logs

# 工具配置
TOOLS_WORKSPACE_DIR=.workspace
TOOLS_MAX_FILE_SIZE=10485760

# CLI 配置
CLI_THEME=dark
CLI_SHOW_PROGRESS=true
```

## 3. 配置加载器

### 3.1 ConfigLoader 实现

```typescript
class ConfigLoader {
  private static readonly CONFIG_PATHS = [
    'config/default.json',
    'config/local.json',
    '.openjragent.json',
    path.join(os.homedir(), '.openjragent', 'config.json')
  ];

  // 加载配置（按优先级合并）
  static load(customPath?: string): GlobalConfig {
    // 1. 加载默认配置
    let config = this.loadDefaultConfig();

    // 2. 加载配置文件
    for (const configPath of this.CONFIG_PATHS) {
      if (fs.existsSync(configPath)) {
        const fileConfig = this.loadConfigFile(configPath);
        config = this.merge(config, fileConfig);
      }
    }

    // 3. 加载自定义配置文件
    if (customPath && fs.existsSync(customPath)) {
      const customConfig = this.loadConfigFile(customPath);
      config = this.merge(config, customConfig);
    }

    // 4. 加载环境变量
    const envConfig = this.loadEnvConfig();
    config = this.merge(config, envConfig);

    // 5. 验证配置
    const validation = this.validate(config);
    if (!validation.valid) {
      throw new ConfigError(
        `Invalid configuration: ${validation.errors.join(', ')}`
      );
    }

    return config;
  }

  // 加载默认配置
  private static loadDefaultConfig(): GlobalConfig {
    return {
      agent: {
        maxIterations: 10,
        enableReflection: true,
        requireConfirmation: true,
        autoSave: true,
        saveInterval: 60000
      },
      llm: {
        planner: {
          provider: 'openai',
          model: 'gpt-4-turbo-preview',
          temperature: 0.7,
          maxTokens: 4096,
          timeout: 60000
        },
        executor: {
          provider: 'openai',
          model: 'gpt-4-turbo-preview',
          temperature: 0.3,
          maxTokens: 4096,
          timeout: 120000
        },
        reflector: {
          provider: 'openai',
          model: 'gpt-3.5-turbo',
          temperature: 0.5,
          maxTokens: 2048,
          timeout: 60000
        }
      },
      tools: {
        enabled: [
          'code_query', 'file_read', 'file_write', 'file_list',
          'snippet_save', 'snippet_load', 'snippet_list',
          'shell_exec', 'ask_user'
        ],
        workspaceDir: '.workspace',
        maxFileSize: 10 * 1024 * 1024,
        allowedExtensions: [
          '.js', '.ts', '.jsx', '.tsx', '.py', '.java',
          '.go', '.rs', '.c', '.cpp', '.h', '.hpp',
          '.json', '.yaml', '.yml', '.md', '.txt'
        ],
        shellTimeout: 30000,
        shellMaxBuffer: 10 * 1024 * 1024
      },
      logging: {
        level: 'info',
        outputDir: 'logs',
        enableConsole: true,
        enableFile: true,
        maxFileSize: 10 * 1024 * 1024,
        maxFiles: 10,
        format: 'json'
      },
      cli: {
        theme: 'dark',
        showProgress: true,
        confirmDangerous: true,
        colorOutput: true,
        verboseErrors: false
      },
      storage: {
        type: 'file',
        snippetDir: '.workspace/snippets',
        sessionDir: '.workspace/sessions'
      }
    };
  }

  // 加载配置文件
  private static loadConfigFile(path: string): DeepPartial<GlobalConfig> {
    try {
      const content = fs.readFileSync(path, 'utf8');
      return JSON.parse(content);
    } catch (error) {
      throw new ConfigError(`Failed to load config file '${path}': ${error.message}`);
    }
  }

  // 加载环境变量配置
  private static loadEnvConfig(): DeepPartial<GlobalConfig> {
    dotenv.config();

    const config: DeepPartial<GlobalConfig> = {};

    // LLM API Keys
    if (process.env.OPENAI_API_KEY) {
      config.llm = config.llm || {};
      config.llm.planner = { ...config.llm.planner, apiKey: process.env.OPENAI_API_KEY };
      config.llm.executor = { ...config.llm.executor, apiKey: process.env.OPENAI_API_KEY };
      config.llm.reflector = { ...config.llm.reflector, apiKey: process.env.OPENAI_API_KEY };
    }

    if (process.env.ANTHROPIC_API_KEY) {
      // 如果配置了 Anthropic，覆盖对应的配置
      // ...
    }

    // Agent 配置
    if (process.env.AGENT_MAX_ITERATIONS) {
      config.agent = config.agent || {};
      config.agent.maxIterations = parseInt(process.env.AGENT_MAX_ITERATIONS);
    }

    if (process.env.AGENT_ENABLE_REFLECTION) {
      config.agent = config.agent || {};
      config.agent.enableReflection = process.env.AGENT_ENABLE_REFLECTION === 'true';
    }

    // 日志配置
    if (process.env.LOG_LEVEL) {
      config.logging = config.logging || {};
      config.logging.level = process.env.LOG_LEVEL as LogLevel;
    }

    // 工具配置
    if (process.env.TOOLS_WORKSPACE_DIR) {
      config.tools = config.tools || {};
      config.tools.workspaceDir = process.env.TOOLS_WORKSPACE_DIR;
    }

    return config;
  }

  // 合并配置（深度合并）
  static merge(
    base: GlobalConfig,
    override: DeepPartial<GlobalConfig>
  ): GlobalConfig {
    return deepMerge(base, override);
  }

  // 验证配置
  static validate(config: GlobalConfig): ValidationResult {
    const errors: string[] = [];

    // 验证 Agent 配置
    if (config.agent.maxIterations < 1 || config.agent.maxIterations > 100) {
      errors.push('agent.maxIterations must be between 1 and 100');
    }

    // 验证 LLM 配置
    for (const role of ['planner', 'executor', 'reflector'] as const) {
      const llmConfig = config.llm[role];

      if (!llmConfig.provider) {
        errors.push(`llm.${role}.provider is required`);
      }

      if (!llmConfig.model) {
        errors.push(`llm.${role}.model is required`);
      }

      if (llmConfig.temperature < 0 || llmConfig.temperature > 2) {
        errors.push(`llm.${role}.temperature must be between 0 and 2`);
      }

      if (llmConfig.maxTokens < 1) {
        errors.push(`llm.${role}.maxTokens must be positive`);
      }
    }

    // 验证工具配置
    if (!config.tools.workspaceDir) {
      errors.push('tools.workspaceDir is required');
    }

    if (config.tools.maxFileSize < 1) {
      errors.push('tools.maxFileSize must be positive');
    }

    // 验证日志配置
    const validLogLevels = ['debug', 'info', 'warn', 'error'];
    if (!validLogLevels.includes(config.logging.level)) {
      errors.push(`logging.level must be one of: ${validLogLevels.join(', ')}`);
    }

    return {
      valid: errors.length === 0,
      errors
    };
  }
}
```

## 4. 多模型配置方案

### 4.1 配置不同角色使用不同模型

```json
{
  "llm": {
    "planner": {
      "provider": "openai",
      "model": "gpt-4-turbo-preview",
      "temperature": 0.7,
      "maxTokens": 4096
    },
    "executor": {
      "provider": "anthropic",
      "model": "claude-3-opus-20240229",
      "temperature": 0.3,
      "maxTokens": 4096
    },
    "reflector": {
      "provider": "openai",
      "model": "gpt-3.5-turbo",
      "temperature": 0.5,
      "maxTokens": 2048
    }
  }
}
```

### 4.2 本地模型配置 (Ollama)

```json
{
  "llm": {
    "planner": {
      "provider": "ollama",
      "model": "llama3:70b",
      "baseURL": "http://localhost:11434",
      "temperature": 0.7,
      "maxTokens": 4096
    },
    "executor": {
      "provider": "ollama",
      "model": "codellama:34b",
      "baseURL": "http://localhost:11434",
      "temperature": 0.3,
      "maxTokens": 4096
    },
    "reflector": {
      "provider": "ollama",
      "model": "llama3:8b",
      "baseURL": "http://localhost:11434",
      "temperature": 0.5,
      "maxTokens": 2048
    }
  }
}
```

### 4.3 成本优化配置

```json
{
  "llm": {
    "planner": {
      "provider": "openai",
      "model": "gpt-4-turbo-preview",
      "temperature": 0.7,
      "maxTokens": 2048
    },
    "executor": {
      "provider": "openai",
      "model": "gpt-3.5-turbo",
      "temperature": 0.3,
      "maxTokens": 4096
    },
    "reflector": {
      "provider": "openai",
      "model": "gpt-3.5-turbo",
      "temperature": 0.5,
      "maxTokens": 1024
    }
  }
}
```

## 5. CLI 参数覆盖

### 5.1 命令行参数定义

```typescript
import { Command } from 'commander';

const program = new Command();

program
  .name('openjragent')
  .description('OpenJRAgent - Automated Programming Agent')
  .version('1.0.0');

program
  .command('run <task>')
  .description('Run agent with a task')
  .option('-c, --config <path>', 'Config file path')
  .option('--max-iterations <number>', 'Maximum iterations', parseInt)
  .option('--no-reflection', 'Disable reflection phase')
  .option('--no-confirmation', 'Skip user confirmation')
  .option('--planner-model <model>', 'Planner model name')
  .option('--executor-model <model>', 'Executor model name')
  .option('--reflector-model <model>', 'Reflector model name')
  .option('--log-level <level>', 'Log level (debug|info|warn|error)')
  .option('--workspace <path>', 'Workspace directory')
  .option('--resume <sessionId>', 'Resume from saved session')
  .action(async (task, options) => {
    // 加载配置
    let config = ConfigLoader.load(options.config);

    // CLI 参数覆盖
    if (options.maxIterations) {
      config.agent.maxIterations = options.maxIterations;
    }

    if (options.reflection === false) {
      config.agent.enableReflection = false;
    }

    if (options.confirmation === false) {
      config.agent.requireConfirmation = false;
    }

    if (options.plannerModel) {
      config.llm.planner.model = options.plannerModel;
    }

    if (options.executorModel) {
      config.llm.executor.model = options.executorModel;
    }

    if (options.reflectorModel) {
      config.llm.reflector.model = options.reflectorModel;
    }

    if (options.logLevel) {
      config.logging.level = options.logLevel;
    }

    if (options.workspace) {
      config.tools.workspaceDir = options.workspace;
    }

    // 运行 Agent
    await runAgent(task, config, options.resume);
  });
```

### 5.2 使用示例

```bash
# 使用默认配置
openjragent run "实现用户登录功能"

# 指定配置文件
openjragent run "实现用户登录功能" --config ./my-config.json

# 覆盖特定参数
openjragent run "实现用户登录功能" \
  --max-iterations 20 \
  --planner-model gpt-4 \
  --executor-model claude-3-opus \
  --log-level debug

# 禁用反思和确认（快速模式）
openjragent run "修复 bug" --no-reflection --no-confirmation

# 恢复之前的会话
openjragent run "继续之前的任务" --resume session-123456
```

## 6. 配置预设

### 6.1 预设配置模板

```typescript
const CONFIG_PRESETS = {
  // 快速模式：使用小模型，禁用反思
  fast: {
    agent: {
      maxIterations: 5,
      enableReflection: false,
      requireConfirmation: false
    },
    llm: {
      planner: { model: 'gpt-3.5-turbo' },
      executor: { model: 'gpt-3.5-turbo' },
      reflector: { model: 'gpt-3.5-turbo' }
    }
  },

  // 高质量模式：使用大模型，启用所有功能
  quality: {
    agent: {
      maxIterations: 15,
      enableReflection: true,
      requireConfirmation: true
    },
    llm: {
      planner: { model: 'gpt-4-turbo-preview' },
      executor: { model: 'claude-3-opus-20240229' },
      reflector: { model: 'gpt-4-turbo-preview' }
    }
  },

  // 本地模式：使用 Ollama 本地模型
  local: {
    llm: {
      planner: { provider: 'ollama', model: 'llama3:70b' },
      executor: { provider: 'ollama', model: 'codellama:34b' },
      reflector: { provider: 'ollama', model: 'llama3:8b' }
    }
  },

  // 经济模式：最小化成本
  economy: {
    agent: {
      maxIterations: 8,
      enableReflection: true
    },
    llm: {
      planner: { model: 'gpt-3.5-turbo', maxTokens: 2048 },
      executor: { model: 'gpt-3.5-turbo', maxTokens: 3072 },
      reflector: { model: 'gpt-3.5-turbo', maxTokens: 1024 }
    }
  }
};

// 使用预设
program
  .command('run <task>')
  .option('--preset <name>', 'Use configuration preset (fast|quality|local|economy)')
  .action(async (task, options) => {
    let config = ConfigLoader.load();

    if (options.preset && CONFIG_PRESETS[options.preset]) {
      config = ConfigLoader.merge(config, CONFIG_PRESETS[options.preset]);
    }

    await runAgent(task, config);
  });
```

## 7. 配置验证器

### 7.1 Schema 定义

```typescript
import Joi from 'joi';

const LLMConfigSchema = Joi.object({
  provider: Joi.string().valid('openai', 'anthropic', 'ollama').required(),
  model: Joi.string().required(),
  apiKey: Joi.string().optional(),
  baseURL: Joi.string().uri().optional(),
  temperature: Joi.number().min(0).max(2).default(0.7),
  maxTokens: Joi.number().min(1).max(128000).default(4096),
  topP: Joi.number().min(0).max(1).optional(),
  timeout: Joi.number().min(1000).max(600000).default(60000)
});

const GlobalConfigSchema = Joi.object({
  agent: Joi.object({
    maxIterations: Joi.number().min(1).max(100).default(10),
    enableReflection: Joi.boolean().default(true),
    requireConfirmation: Joi.boolean().default(true),
    autoSave: Joi.boolean().default(true),
    saveInterval: Joi.number().min(1000).default(60000)
  }),

  llm: Joi.object({
    planner: LLMConfigSchema,
    executor: LLMConfigSchema,
    reflector: LLMConfigSchema
  }),

  tools: Joi.object({
    enabled: Joi.array().items(Joi.string()).default([]),
    workspaceDir: Joi.string().required(),
    maxFileSize: Joi.number().min(1).default(10485760),
    allowedExtensions: Joi.array().items(Joi.string()).default([]),
    shellTimeout: Joi.number().min(1000).default(30000),
    shellMaxBuffer: Joi.number().min(1).default(10485760)
  }),

  logging: Joi.object({
    level: Joi.string().valid('debug', 'info', 'warn', 'error').default('info'),
    outputDir: Joi.string().default('logs'),
    enableConsole: Joi.boolean().default(true),
    enableFile: Joi.boolean().default(true),
    maxFileSize: Joi.number().min(1).default(10485760),
    maxFiles: Joi.number().min(1).default(10),
    format: Joi.string().valid('json', 'text').default('json')
  }),

  cli: Joi.object({
    theme: Joi.string().valid('light', 'dark').default('dark'),
    showProgress: Joi.boolean().default(true),
    confirmDangerous: Joi.boolean().default(true),
    colorOutput: Joi.boolean().default(true),
    verboseErrors: Joi.boolean().default(false)
  }),

  storage: Joi.object({
    type: Joi.string().valid('file', 'memory').default('file'),
    snippetDir: Joi.string().default('.workspace/snippets'),
    sessionDir: Joi.string().default('.workspace/sessions')
  })
});

class ConfigValidator {
  static validate(config: any): ValidationResult {
    const result = GlobalConfigSchema.validate(config, {
      abortEarly: false,
      allowUnknown: false
    });

    if (result.error) {
      return {
        valid: false,
        errors: result.error.details.map(d => d.message)
      };
    }

    return {
      valid: true,
      errors: []
    };
  }
}
```

## 8. 配置热更新

### 8.1 配置监听器

```typescript
import chokidar from 'chokidar';

class ConfigWatcher {
  private watcher: chokidar.FSWatcher;
  private config: GlobalConfig;
  private listeners: Array<(config: GlobalConfig) => void> = [];

  constructor(configPath: string) {
    this.config = ConfigLoader.load(configPath);

    // 监听配置文件变化
    this.watcher = chokidar.watch(configPath, {
      persistent: true,
      ignoreInitial: true
    });

    this.watcher.on('change', async () => {
      try {
        const newConfig = ConfigLoader.load(configPath);
        this.config = newConfig;

        // 通知所有监听器
        for (const listener of this.listeners) {
          listener(newConfig);
        }

        logger.info('Configuration reloaded');
      } catch (error) {
        logger.error('Failed to reload configuration', error);
      }
    });
  }

  // 订阅配置变化
  onChange(listener: (config: GlobalConfig) => void): void {
    this.listeners.push(listener);
  }

  // 获取当前配置
  getConfig(): GlobalConfig {
    return this.config;
  }

  // 停止监听
  stop(): void {
    this.watcher.close();
  }
}
```

## 9. 配置导出与分享

### 9.1 导出配置

```typescript
class ConfigExporter {
  // 导出当前配置（移除敏感信息）
  static export(config: GlobalConfig): string {
    const sanitized = this.sanitize(config);
    return JSON.stringify(sanitized, null, 2);
  }

  // 移除敏感信息
  private static sanitize(config: GlobalConfig): any {
    const sanitized = JSON.parse(JSON.stringify(config));

    // 移除 API Keys
    if (sanitized.llm) {
      for (const role of ['planner', 'executor', 'reflector']) {
        if (sanitized.llm[role]?.apiKey) {
          sanitized.llm[role].apiKey = '***';
        }
      }
    }

    return sanitized;
  }

  // 导入配置
  static import(configString: string): GlobalConfig {
    const config = JSON.parse(configString);
    const validation = ConfigLoader.validate(config);

    if (!validation.valid) {
      throw new ConfigError(`Invalid configuration: ${validation.errors.join(', ')}`);
    }

    return config;
  }
}

// CLI 命令
program
  .command('config:export')
  .description('Export current configuration')
  .option('-o, --output <path>', 'Output file path')
  .action((options) => {
    const config = ConfigLoader.load();
    const exported = ConfigExporter.export(config);

    if (options.output) {
      fs.writeFileSync(options.output, exported);
      console.log(`Configuration exported to ${options.output}`);
    } else {
      console.log(exported);
    }
  });
```

## 10. 配置最佳实践

### 10.1 推荐配置

```json
{
  "agent": {
    "maxIterations": 10,
    "enableReflection": true,
    "requireConfirmation": true
  },
  "llm": {
    "planner": {
      "provider": "openai",
      "model": "gpt-4-turbo-preview",
      "temperature": 0.7
    },
    "executor": {
      "provider": "anthropic",
      "model": "claude-3-opus-20240229",
      "temperature": 0.3
    },
    "reflector": {
      "provider": "openai",
      "model": "gpt-3.5-turbo",
      "temperature": 0.5
    }
  }
}
```

### 10.2 配置优化建议

- **Planner**: 使用较高 temperature (0.7-0.8) 以获得更多创造性
- **Executor**: 使用较低 temperature (0.2-0.4) 以确保准确性
- **Reflector**: 使用中等 temperature (0.5-0.6) 平衡评估
- **成本优化**: Reflector 可使用小模型（如 GPT-3.5）
- **质量优先**: 所有角色使用大模型（如 GPT-4、Claude Opus）
